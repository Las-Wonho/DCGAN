{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haho6\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "images = []\n",
    "for i in range(470):\n",
    "    image = load_img('./DATA/'+str(i)+'.jpeg',target_size=(64,64))\n",
    "    image = img_to_array(image)\n",
    "    image.shape\n",
    "    image = image / 256\n",
    "    images.append(image)\n",
    "    \n",
    "    \n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-3., 3., size = [batch_size, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowUp(arr):\n",
    "    import cv2\n",
    "    frame = cv2.cvtColor(np.array(arr), cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 64,64,3])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "Z = tf.placeholder(tf.float32, [None, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(Z):\n",
    "    w1 = tf.Variable(tf.random_normal([100, 16384]))\n",
    "    h1 = tf.matmul(Z,w1)\n",
    "    re = tf.reshape(h1,[-1,4,4,1024])\n",
    "    re = tf.layers.batch_normalization(re)\n",
    "\n",
    "    conv_h1 = tf.layers.conv2d_transpose(re ,512, 5, 2, padding='same')\n",
    "    conv_h1 = tf.nn.relu(conv_h1)\n",
    "\n",
    "    conv_h2 = tf.layers.conv2d_transpose(conv_h1 ,256, 4, 2, padding='same')\n",
    "    conv_h2 = tf.nn.relu(conv_h2)\n",
    "\n",
    "    conv_h3 = tf.layers.conv2d_transpose(conv_h2 ,128, 4, 2, padding='same')\n",
    "    conv_h3 = tf.nn.relu(conv_h3)\n",
    "    \n",
    "#    conv_h4 = tf.layers.conv2d_transpose(conv_h3 ,64, 4, 2, padding='same')\n",
    "#    conv_h4 = tf.nn.relu(conv_h4)\n",
    "    \n",
    "    conv_h6 = tf.layers.conv2d_transpose(conv_h3 ,3, 4, 2, padding='same')\n",
    "    return conv_h6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminaster(inputs):\n",
    "        W1 = tf.Variable(tf.random_normal([3,3,3,32],stddev=0.02))\n",
    "        H1 = tf.nn.conv2d(inputs,W1, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        H1 = tf.layers.batch_normalization(H1)\n",
    "        H1 = tf.nn.relu(H1)\n",
    "\n",
    "        W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.02))\n",
    "        H2 = tf.nn.conv2d(H1,W2, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        H2 = tf.nn.relu(H2)\n",
    "\n",
    "        W3 = tf.Variable(tf.random_normal([3,3,64,256],stddev=0.02))\n",
    "        H3 = tf.nn.conv2d(H2,W3, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        H3 = tf.nn.relu(H3)\n",
    "\n",
    "        out = tf.reshape(H3,[-1,16384])\n",
    "        out = tf.layers.dense(out,1)\n",
    "        D = [W1, W2, W3]\n",
    "        return out, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generate(Z)\n",
    "D_real = discriminaster(X)\n",
    "D_gene = discriminaster(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real,labels=tf.ones_like(D_real)))\n",
    "\n",
    "loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene,labels=tf.zeros_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta_D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-34c62bef0c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mD_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_real\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_gene\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mG_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_gene\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclip_D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtheta_D\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'theta_D' is not defined"
     ]
    }
   ],
   "source": [
    "D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_gene)\n",
    "G_loss = -tf.reduce_mean(D_gene)\n",
    "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_solver = (tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "            .minimize(-D_loss, var_list=theta_D))\n",
    "G_solver = (tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "            .minimize(G_loss, var_list=theta_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = loss_D_gene + loss_D_real\n",
    "loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.ones_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(0.01).minimize(loss_D)\n",
    "train_G = tf.train.AdamOptimizer(0.01).minimize(loss_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   D : 0.5320679\t G : 0.8907993\n",
      "1   D : 0.53206587\t G : 0.8908027\n",
      "2   D : 0.5320638\t G : 0.8908061\n",
      "3   D : 0.5320618\t G : 0.89080954\n",
      "4   D : 0.5320598\t G : 0.8908129\n",
      "5   D : 0.5320578\t G : 0.8908162\n",
      "6   D : 0.532056\t G : 0.89081943\n",
      "7   D : 0.53205407\t G : 0.8908227\n",
      "8   D : 0.53205216\t G : 0.890826\n",
      "9   D : 0.5320503\t G : 0.8908291\n",
      "10   D : 0.53204846\t G : 0.8908322\n",
      "11   D : 0.5320466\t G : 0.8908353\n",
      "12   D : 0.5320449\t G : 0.8908384\n",
      "13   D : 0.53204304\t G : 0.8908414\n",
      "14   D : 0.5320413\t G : 0.89084446\n",
      "15   D : 0.53203964\t G : 0.8908474\n",
      "16   D : 0.532038\t G : 0.8908503\n",
      "17   D : 0.53203624\t G : 0.8908533\n",
      "18   D : 0.5320346\t G : 0.8908561\n",
      "19   D : 0.53203297\t G : 0.89085895\n",
      "20   D : 0.53203136\t G : 0.89086175\n",
      "21   D : 0.53202975\t G : 0.89086455\n",
      "22   D : 0.53202814\t G : 0.89086735\n",
      "23   D : 0.53202665\t G : 0.89087003\n",
      "24   D : 0.5320251\t G : 0.8908727\n",
      "25   D : 0.5320236\t G : 0.89087534\n",
      "26   D : 0.5320221\t G : 0.8908781\n",
      "27   D : 0.53202057\t G : 0.8908807\n",
      "28   D : 0.5320192\t G : 0.8908832\n",
      "29   D : 0.5320177\t G : 0.89088583\n",
      "30   D : 0.53201634\t G : 0.89088833\n",
      "31   D : 0.5320149\t G : 0.89089084\n",
      "32   D : 0.53201354\t G : 0.89089334\n",
      "33   D : 0.53201216\t G : 0.8908957\n",
      "34   D : 0.5320108\t G : 0.8908981\n",
      "35   D : 0.5320095\t G : 0.8909005\n",
      "36   D : 0.5320082\t G : 0.89090294\n",
      "37   D : 0.53200686\t G : 0.89090526\n",
      "38   D : 0.5320056\t G : 0.8909075\n",
      "39   D : 0.53200436\t G : 0.89090985\n",
      "40   D : 0.5320031\t G : 0.8909122\n",
      "41   D : 0.53200185\t G : 0.89091444\n",
      "42   D : 0.5320006\t G : 0.8909166\n",
      "43   D : 0.5319994\t G : 0.89091885\n",
      "44   D : 0.5319983\t G : 0.890921\n",
      "45   D : 0.5319971\t G : 0.89092314\n",
      "46   D : 0.53199595\t G : 0.8909253\n",
      "47   D : 0.53199476\t G : 0.8909274\n",
      "48   D : 0.5319937\t G : 0.8909294\n",
      "49   D : 0.53199255\t G : 0.8909315\n",
      "50   D : 0.5319915\t G : 0.8909335\n",
      "51   D : 0.5319904\t G : 0.89093554\n",
      "52   D : 0.53198934\t G : 0.89093757\n",
      "53   D : 0.5319883\t G : 0.8909395\n",
      "54   D : 0.53198725\t G : 0.89094144\n",
      "55   D : 0.53198624\t G : 0.89094335\n",
      "56   D : 0.5319852\t G : 0.8909453\n",
      "57   D : 0.53198427\t G : 0.8909472\n",
      "58   D : 0.53198326\t G : 0.8909491\n",
      "59   D : 0.5319823\t G : 0.890951\n",
      "60   D : 0.53198135\t G : 0.8909528\n",
      "61   D : 0.5319804\t G : 0.8909546\n",
      "62   D : 0.53197944\t G : 0.8909564\n",
      "63   D : 0.53197855\t G : 0.8909582\n",
      "64   D : 0.5319776\t G : 0.89096\n",
      "65   D : 0.53197676\t G : 0.8909617\n",
      "66   D : 0.53197587\t G : 0.8909634\n",
      "67   D : 0.531975\t G : 0.8909651\n",
      "68   D : 0.5319741\t G : 0.8909668\n",
      "69   D : 0.53197324\t G : 0.8909685\n",
      "70   D : 0.5319724\t G : 0.8909701\n",
      "71   D : 0.53197163\t G : 0.8909718\n",
      "72   D : 0.53197086\t G : 0.8909733\n",
      "73   D : 0.53197\t G : 0.89097494\n",
      "74   D : 0.5319692\t G : 0.89097655\n",
      "75   D : 0.5319685\t G : 0.8909781\n",
      "76   D : 0.5319677\t G : 0.89097965\n",
      "77   D : 0.5319669\t G : 0.8909812\n",
      "78   D : 0.53196615\t G : 0.89098275\n",
      "79   D : 0.53196543\t G : 0.8909842\n",
      "80   D : 0.5319647\t G : 0.8909857\n",
      "81   D : 0.531964\t G : 0.8909872\n",
      "82   D : 0.5319633\t G : 0.8909886\n",
      "83   D : 0.5319626\t G : 0.89099014\n",
      "84   D : 0.5319619\t G : 0.8909915\n",
      "85   D : 0.5319612\t G : 0.890993\n",
      "86   D : 0.53196055\t G : 0.8909943\n",
      "87   D : 0.53195995\t G : 0.89099574\n",
      "88   D : 0.53195924\t G : 0.89099705\n",
      "89   D : 0.5319587\t G : 0.8909985\n",
      "90   D : 0.531958\t G : 0.8909998\n",
      "91   D : 0.5319574\t G : 0.8910011\n",
      "92   D : 0.5319568\t G : 0.8910024\n",
      "93   D : 0.53195614\t G : 0.8910038\n",
      "94   D : 0.5319556\t G : 0.89100504\n",
      "95   D : 0.53195494\t G : 0.89100635\n",
      "96   D : 0.5319544\t G : 0.8910076\n",
      "97   D : 0.5319539\t G : 0.89100885\n",
      "98   D : 0.5319533\t G : 0.89101005\n",
      "99   D : 0.53195274\t G : 0.8910113\n",
      "100   D : 0.53195214\t G : 0.89101255\n",
      "101   D : 0.53195167\t G : 0.89101374\n",
      "102   D : 0.5319511\t G : 0.8910149\n",
      "103   D : 0.53195053\t G : 0.8910161\n",
      "104   D : 0.53195\t G : 0.8910173\n",
      "105   D : 0.5319496\t G : 0.8910185\n",
      "106   D : 0.53194904\t G : 0.8910196\n",
      "107   D : 0.5319485\t G : 0.8910208\n",
      "108   D : 0.53194803\t G : 0.89102185\n",
      "109   D : 0.5319476\t G : 0.891023\n",
      "110   D : 0.53194714\t G : 0.8910241\n",
      "111   D : 0.53194666\t G : 0.8910252\n",
      "112   D : 0.5319462\t G : 0.89102626\n",
      "113   D : 0.5319457\t G : 0.89102733\n",
      "114   D : 0.5319453\t G : 0.8910284\n",
      "115   D : 0.5319449\t G : 0.8910295\n",
      "116   D : 0.5319444\t G : 0.89103055\n",
      "117   D : 0.531944\t G : 0.8910315\n",
      "118   D : 0.53194356\t G : 0.89103246\n",
      "119   D : 0.53194314\t G : 0.89103353\n",
      "120   D : 0.5319427\t G : 0.8910346\n",
      "121   D : 0.5319423\t G : 0.89103556\n",
      "122   D : 0.53194195\t G : 0.8910365\n",
      "123   D : 0.5319416\t G : 0.89103746\n",
      "124   D : 0.5319412\t G : 0.8910385\n",
      "125   D : 0.53194076\t G : 0.8910394\n",
      "126   D : 0.5319404\t G : 0.8910403\n",
      "127   D : 0.53194004\t G : 0.8910413\n",
      "128   D : 0.5319396\t G : 0.89104223\n",
      "129   D : 0.5319393\t G : 0.8910432\n",
      "130   D : 0.53193897\t G : 0.891044\n",
      "131   D : 0.5319386\t G : 0.891045\n",
      "132   D : 0.53193825\t G : 0.89104587\n",
      "133   D : 0.53193796\t G : 0.8910468\n",
      "134   D : 0.5319376\t G : 0.89104766\n",
      "135   D : 0.53193724\t G : 0.89104855\n",
      "136   D : 0.53193694\t G : 0.8910494\n",
      "137   D : 0.5319367\t G : 0.8910503\n",
      "138   D : 0.53193635\t G : 0.8910511\n",
      "139   D : 0.53193605\t G : 0.89105195\n",
      "140   D : 0.5319357\t G : 0.8910528\n",
      "141   D : 0.53193545\t G : 0.8910537\n",
      "142   D : 0.53193516\t G : 0.89105445\n",
      "143   D : 0.53193486\t G : 0.8910553\n",
      "144   D : 0.5319346\t G : 0.89105606\n",
      "145   D : 0.5319343\t G : 0.89105684\n",
      "146   D : 0.531934\t G : 0.8910576\n",
      "147   D : 0.5319337\t G : 0.89105844\n",
      "148   D : 0.5319335\t G : 0.89105916\n",
      "149   D : 0.53193325\t G : 0.89106\n",
      "150   D : 0.53193295\t G : 0.8910607\n",
      "151   D : 0.5319327\t G : 0.8910614\n",
      "152   D : 0.5319325\t G : 0.89106214\n",
      "153   D : 0.53193223\t G : 0.891063\n",
      "154   D : 0.531932\t G : 0.8910637\n",
      "155   D : 0.5319318\t G : 0.89106435\n",
      "156   D : 0.5319315\t G : 0.89106506\n",
      "157   D : 0.5319313\t G : 0.89106584\n",
      "158   D : 0.5319311\t G : 0.89106655\n",
      "159   D : 0.5319309\t G : 0.89106727\n",
      "160   D : 0.5319307\t G : 0.89106786\n",
      "161   D : 0.5319305\t G : 0.8910686\n",
      "162   D : 0.53193027\t G : 0.8910693\n",
      "163   D : 0.5319301\t G : 0.89106995\n",
      "164   D : 0.53192985\t G : 0.8910706\n",
      "165   D : 0.5319297\t G : 0.89107126\n",
      "166   D : 0.5319295\t G : 0.8910719\n",
      "167   D : 0.53192925\t G : 0.89107263\n",
      "168   D : 0.53192914\t G : 0.8910732\n",
      "169   D : 0.5319289\t G : 0.8910739\n",
      "170   D : 0.5319287\t G : 0.8910745\n",
      "171   D : 0.5319286\t G : 0.89107513\n",
      "172   D : 0.5319284\t G : 0.89107573\n",
      "173   D : 0.5319283\t G : 0.8910764\n",
      "174   D : 0.53192806\t G : 0.891077\n",
      "175   D : 0.5319279\t G : 0.89107764\n",
      "176   D : 0.53192776\t G : 0.89107823\n",
      "177   D : 0.5319276\t G : 0.8910788\n",
      "178   D : 0.53192747\t G : 0.8910794\n",
      "179   D : 0.5319273\t G : 0.89108\n",
      "180   D : 0.53192717\t G : 0.8910806\n",
      "181   D : 0.531927\t G : 0.8910812\n",
      "182   D : 0.5319269\t G : 0.8910817\n",
      "183   D : 0.53192675\t G : 0.89108235\n",
      "184   D : 0.53192663\t G : 0.8910829\n",
      "185   D : 0.53192645\t G : 0.8910835\n",
      "186   D : 0.53192633\t G : 0.8910841\n",
      "187   D : 0.5319262\t G : 0.89108455\n",
      "188   D : 0.53192604\t G : 0.8910851\n",
      "189   D : 0.531926\t G : 0.8910856\n",
      "190   D : 0.53192586\t G : 0.8910862\n",
      "191   D : 0.5319257\t G : 0.8910867\n",
      "192   D : 0.5319256\t G : 0.8910873\n",
      "193   D : 0.5319255\t G : 0.89108783\n",
      "194   D : 0.5319253\t G : 0.8910883\n",
      "195   D : 0.5319252\t G : 0.8910889\n",
      "196   D : 0.53192514\t G : 0.8910894\n",
      "197   D : 0.5319251\t G : 0.8910899\n",
      "198   D : 0.5319249\t G : 0.8910904\n",
      "199   D : 0.5319248\t G : 0.89109087\n"
     ]
    }
   ],
   "source": [
    "im = images[250:350]\n",
    "\n",
    "for i in range(200):\n",
    "    noise = get_noise(1,100)\n",
    "    _, varsD=sess.run([train_D, loss_D], \n",
    "                  feed_dict={\n",
    "                      X:im,\n",
    "                      Z: noise})\n",
    "    \n",
    "    _, varsG=sess.run([train_G, loss_G], \n",
    "                  feed_dict={\n",
    "                      X:im,\n",
    "                      Z: noise})\n",
    "    print(str(i)+\"   D : \"+str(varsD)+\"\\t G : \"+str(varsG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise = get_noise(20,100)\n",
    "i = sess.run(G, feed_dict={Z:noise})\n",
    "for row in range(20):\n",
    "    windowUp(i[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = get_noise(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
